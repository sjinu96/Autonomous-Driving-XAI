{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bfc729e",
   "metadata": {},
   "source": [
    "# Adversarial Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0e7f3e",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2458a00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1000b2d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf3b0963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting click\n",
      "  Using cached click-8.0.1-py3-none-any.whl (97 kB)\n",
      "Requirement already satisfied: importlib-metadata in /home/jrkim/.conda/envs/jsp_vinet/lib/python3.7/site-packages (from click) (3.10.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/jrkim/.conda/envs/jsp_vinet/lib/python3.7/site-packages (from importlib-metadata->click) (3.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /home/jrkim/.conda/envs/jsp_vinet/lib/python3.7/site-packages (from importlib-metadata->click) (3.7.4.3)\n",
      "Installing collected packages: click\n",
      "Successfully installed click-8.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install click"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffc44f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "import torch\n",
    "\n",
    "### local imports\n",
    "import model\n",
    "\n",
    "\n",
    "### Environment imports\n",
    "import click # Class object() 대신 argument 조절 library 사용\n",
    "import math\n",
    "import os\n",
    "import shutil # 고수준 파일 연산\n",
    "import torch\n",
    "import torch.utils.data.dataset\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3581f774",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Configuration settings\n",
    "# Resnet의 기본 학습 단계이다. \n",
    "# Training rate / size parameters\n",
    "TRAIN_BATCHSIZE = 128  # GPU 개수에 따라 배수로 조절해도 됨.\n",
    "TRAIN_LR = 0.1  # GPU 개수에 따라 배수로 조절해도 됨. --> ?\n",
    "TRAIN_MOMENTUM = 0.9 #  --> (SGD optimizer 사용)\n",
    "TRAIN_WEIGHT_DECAY = 1e-4 # --> (SGD optimizer 사용)\n",
    "TRAIN_EPOCHS = [170, 195, 200]  # Divide lr by 10 at each; finish after last. --> 해당 epoch이 될 때마다 학습률을 0.1배\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01458e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adversarial training settings\n",
    "# 적대적 훈련은 노이즈에 대한 L2 loss를 최소화함\n",
    "# 동시에 번갈아가면서 class에서 멀어지도록 gradient ascent를 진행..\n",
    "TRAIN_ADV_EPS = 0.01 # 적대적 설명을 사용한다.\n",
    "TRAIN_ADV_L2MIN_EPS = 0.1 # 적대적 설명을 사용할 때 L2 MIN도 사용가능."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f326ef37",
   "metadata": {},
   "source": [
    "#### 추가적 이해 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4eeae06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adversarial robustness parameters\n",
    "ROBUST_Z = 2\n",
    "ROBUST_ZETA = 0.2  # 항상 쌍으로 이루어진다(tandem).\n",
    "ROBUST_ADAPT_L_TARGET = 1.5\n",
    "ROBUST_ADAPT_PSI_0 = 220\n",
    "ROBUST_ADAPT_PSI = 0.02\n",
    "ROBUST_ADAPT_EPS_POS = 1\n",
    "ROBUST_ADAPT_EPS_NEG = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5d7ed6",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404e3ec0",
   "metadata": {},
   "source": [
    "### How to reset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b60d6cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Offset as [mean, std] of data input. --> ( resnet 때문에 투입)\n",
    "MODEL_INPUT_OFFSET = [[0.4914, 0.4822, 0.4465], [0.247, 0.243, 0.261]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cddd58",
   "metadata": {},
   "source": [
    "### 네트워크 구조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cafae4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bdd100k_preprocess(ft_out):\n",
    "    return torch.nn.Conv2d(3, ft_out, kernel_size=3, padding=1, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ac80bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ARCH=[\n",
    "    32, # input size, 정사각형 가정\n",
    "    bdd100k_preprocess, #Resnet의 initial layer.\n",
    "    [(44 - 2)//6 for _ in range(3)],# [7,7,7],  Block Length --> ( ... ) \n",
    "    [16, 32, 64], # feature의 개수들.\n",
    "    11,  # class 개수 (BDD-1000k)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5570dc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Low-resource computer를 위한 실험 (우선 배제)\n",
    "# ONE_BATCH_ONLY = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bde9449",
   "metadata": {},
   "source": [
    "## dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61248fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list=['trailer', 'motorcycle', 'bicycle', 'car', 'bus', 'other vehicle', 'pedestrian', 'other person', 'truck', 'train', 'rider']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e106ce53",
   "metadata": {},
   "outputs": [],
   "source": [
    "root='../BDD100K_MOT2020_image/bdd100k/images/track/train_av'\n",
    "root_test='../BDD100K_MOT2020_image/bdd100k/images/track/test_av'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b1419d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9575fbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "train_dataset = ImageFolder(root='./dataset', transform=transform_train)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                           batch_size=128, shuffle=True, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20c77f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # # CIFAR-10 찾기\n",
    "# # # # CIFAR10_PATH에 관한 환경변수가 없다면 None을 반환한다.\n",
    "# # # cifar10_path = os.environ.get('CIFAR10_PATH', '')\n",
    "\n",
    "# # if not cifar10_path.strip():\n",
    "# # #     raise ValueError('Must specify CIFAR10_PATH environment variable.')\n",
    "\n",
    "# cifar10_path='CIFAR10_PATH/'\n",
    "\n",
    "# # 경로설정\n",
    "# if not os.path.exists(cifar10_path):\n",
    "#     os.mkdir(cifar10_path)\n",
    "# # dataset 다운로드\n",
    "# if len(os.listdir(cifar10_path))==0:\n",
    "#     torchvision.datasets.CIFAR10(cifar10_path, download=True)\n",
    "\n",
    "# # Labels\n",
    "# class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog',\n",
    "#         'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430ae2cc",
   "metadata": {},
   "source": [
    "### main.py 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b23675",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
